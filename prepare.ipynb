{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135f7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475da894",
   "metadata": {},
   "source": [
    "### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "> - Lowercase everything\n",
    "> - Normalize unicode characters\n",
    "> - Replace anything that is not a letter, number, whitespace or a single quote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b701a786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = \"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed \\\n",
    "a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), \\\n",
    "but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\"\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb612ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(original):\n",
    "    #cast to lower case\n",
    "    article = original.lower()\n",
    "    #remove accented and non Ascii characters\n",
    "    article = unicodedata.normalize(\"NFKD\", article)\\\n",
    "            .encode(\"ascii\", \"ignore\")\\\n",
    "            .decode(\"utf-8\")\n",
    "    # remove special characters\n",
    "    article = re.sub(r'[^a-z0-9\\'\\s]',\"\", article)\n",
    "    \n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e60094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos's name contains the hungarian letter 'o' 'o' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e318a",
   "metadata": {},
   "source": [
    "### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe377f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(article):\n",
    "    #create tokenizer\n",
    "    tokenize = nltk.tokenize.ToktokTokenizer()\n",
    "    #use tokenizer\n",
    "    article = tokenize.tokenize(article, return_str=True)\n",
    "    \n",
    "    return article\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f12d796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = basic_clean(original)\n",
    "tokenize(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6853bb",
   "metadata": {},
   "source": [
    "### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d03b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(article):\n",
    "    #create porter stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    #apply stemmer\n",
    "    #this is going to give out a list\n",
    "    stems = [ps.stem(word) for word in article.split()]\n",
    "    #join the list back together\n",
    "    article_stemmed = \" \".join(stems)\n",
    "    \n",
    "    return article_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2cfa9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdo and georg polya are influenti hungarian mathematician who contribut a lot to the field erdo ' s name contain the hungarian letter ' o ' ' o ' with doubl acut accent but is often incorrectli written as erdo or erdo either by mistak or out of typograph necess\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = basic_clean(original)\n",
    "article = tokenize(article)\n",
    "article_stemmed = stem(article)\n",
    "article_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a832a88",
   "metadata": {},
   "source": [
    "### 4.Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c4c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(article):\n",
    "    #create lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    #use lemmatizer\n",
    "    #splits back a list of words\n",
    "    lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "    #join word back together\n",
    "    article_lemmatized = \" \".join(lemmas)\n",
    "    \n",
    "    return article_lemmatized\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0736f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematician who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written a erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = basic_clean(original)\n",
    "article = tokenize(article)\n",
    "article_lemmatized = lemmatize(article)\n",
    "article_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc75702",
   "metadata": {},
   "source": [
    "### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c0724ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save stopwords\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad34e3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'and',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'are',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the lemmatised version\n",
    "words = article_lemmatized.split()\n",
    "words[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b22a066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word count\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d88f09a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'contributed',\n",
       " 'lot']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtered words is words minus the stopwords\n",
    "filtered_words = [word for word in words if word not in stopwords_list]\n",
    "filtered_words[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "880b4063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70790f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(article_lemmatized):\n",
    "    # define stopword\n",
    "    stopwords_list = stopwords.words(\"english\")\n",
    "    #split lemmaztised paragraph \n",
    "    words = article_lemmatized.split() \n",
    "    #give me everything that is not stopword\n",
    "    filtered_words = [word for word in words if word not in stopwords_list]\n",
    "    #join filtered words\n",
    "    article_without_stopwords = \" \".join(filtered_words)\n",
    "    \n",
    "    return article_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5bd164b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos george polya influential hungarian mathematician contributed lot field erdos ' name contains hungarian letter ' ' ' ' double acute accent often incorrectly written erdos erdos either mistake typographical necessity\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(article_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cd026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1500534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee520f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483691ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://inshorts.com/en/read\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbdcad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zimbabwe players ask India for cricketing tips</td>\n",
       "      <td>india</td>\n",
       "      <td>After getting thrashed by India by 5-0 in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nigerian weightlifter in dope net, India may gain</td>\n",
       "      <td>india</td>\n",
       "      <td>India may move up after Nigerian weightlifter ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indian Navy gets VLF, easy communication with ...</td>\n",
       "      <td>india</td>\n",
       "      <td>The Indian navy has a new communication system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India beat NZ 3-2 to enter CWG hockey finals</td>\n",
       "      <td>india</td>\n",
       "      <td>In the CWG men's hockey semi-final against New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India's first Billiards Premier League</td>\n",
       "      <td>india</td>\n",
       "      <td>The Billiards and Snooker Association of Mahar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Porsche becomes Europe's most valuable automak...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>Porsche overtook parent company Volkswagen to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Fix for wheel issue that caused electric car r...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>Toyota Motor said it has found a fix for the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Vehicle registrations during festivals doubled...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>Vehicle registrations more than doubled in thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Vintage cars on display to promote wildlife pr...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>To create awareness about wildlife week, the K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Amazon-backed Rivian's shares fall 9% after it...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>Amazon-backed EV-maker Rivian on Friday recall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title    category  \\\n",
       "0       Zimbabwe players ask India for cricketing tips       india   \n",
       "1    Nigerian weightlifter in dope net, India may gain       india   \n",
       "2    Indian Navy gets VLF, easy communication with ...       india   \n",
       "3         India beat NZ 3-2 to enter CWG hockey finals       india   \n",
       "4               India's first Billiards Premier League       india   \n",
       "..                                                 ...         ...   \n",
       "280  Porsche becomes Europe's most valuable automak...  automobile   \n",
       "281  Fix for wheel issue that caused electric car r...  automobile   \n",
       "282  Vehicle registrations during festivals doubled...  automobile   \n",
       "283  Vintage cars on display to promote wildlife pr...  automobile   \n",
       "284  Amazon-backed Rivian's shares fall 9% after it...  automobile   \n",
       "\n",
       "                                                  body  \n",
       "0    After getting thrashed by India by 5-0 in the ...  \n",
       "1    India may move up after Nigerian weightlifter ...  \n",
       "2    The Indian navy has a new communication system...  \n",
       "3    In the CWG men's hockey semi-final against New...  \n",
       "4    The Billiards and Snooker Association of Mahar...  \n",
       "..                                                 ...  \n",
       "280  Porsche overtook parent company Volkswagen to ...  \n",
       "281  Toyota Motor said it has found a fix for the d...  \n",
       "282  Vehicle registrations more than doubled in thi...  \n",
       "283  To create awareness about wildlife week, the K...  \n",
       "284  Amazon-backed EV-maker Rivian on Friday recall...  \n",
       "\n",
       "[285 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquire.get_all_shorts(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4109f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://codeup.com/blog/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b72c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coding Bootcamp or Computer Science Degree?</td>\n",
       "      <td>For many people, deciding between a coding boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diversity Equity and Inclusion Report</td>\n",
       "      <td>Codeup is excited to launch our first Diversit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Codeup Honored as SABJ Diversity and Inclusion...</td>\n",
       "      <td>Codeup has been named the 2022 Diversity and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How Can I Finance My Career Transition?</td>\n",
       "      <td>Deciding to transition into a tech career is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tips for Women Beginning a Career in Tech</td>\n",
       "      <td>Codeup strongly values diversity, and inclusio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is Cloud Computing and AWS?</td>\n",
       "      <td>With many companies switching to cloud service...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0        Coding Bootcamp or Computer Science Degree?   \n",
       "1              Diversity Equity and Inclusion Report   \n",
       "2  Codeup Honored as SABJ Diversity and Inclusion...   \n",
       "3            How Can I Finance My Career Transition?   \n",
       "4          Tips for Women Beginning a Career in Tech   \n",
       "5                   What is Cloud Computing and AWS?   \n",
       "\n",
       "                                             content  \n",
       "0  For many people, deciding between a coding boo...  \n",
       "1  Codeup is excited to launch our first Diversit...  \n",
       "2  Codeup has been named the 2022 Diversity and I...  \n",
       "3  Deciding to transition into a tech career is a...  \n",
       "4  Codeup strongly values diversity, and inclusio...  \n",
       "5  With many companies switching to cloud service...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquire.get_blog_content(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976104cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
